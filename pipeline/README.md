# Choirless Rendering Pipeline

## The rendering pipeline

The rendering pipeline is triggered by dropping files into S3 buckets. The Lambdas will typically call another Lambda and write a file to another bucket.

### raw bucket

A `.webm` file of the form `<choirid>+<songid>+<partid>.webm` is uploaded into the `raw` bucket from the Choirless front end after a choir member has made a recording. Each song part will have a matching document in the database with an id of `<choirid>:song:<songid>:part:<partid>`.

If the song's `partType` is `backing`, then it is the backing track (there's only one backing track per song). All other song parts will have a `partType` of `reference` or `rendition`.

Uploading to the `raw` bucket triggers the `snapshot` Lambda which turns the video into a jpg in the `snapshots` bucket. This Lambda, in turn, calls the 
`convert_format` Lambda to convert the file into a common file format in the `converted` bucket.

### converted bucket

(**Note: At the moment the calculate_alignment Lambda does nothing except call the next Lambda (Renderer)**)
Once the video file is converted into the right format `calculate_alignment` calculates how many milliseconds "off" the part is from the backing part (if this _is_ the backing part then the offset is 0). The offset calculation is written back to the database as the `offset` field and the `renderer` Lambda is called which fetches all the song parts for this song from the database and writes a rendering "plan" to the `definition` bucket. The definition JSON file contains all the details needed to render the final video:

- how big each video should be
- where on the canvas it should be placed
- how loud it should be
- what time offset should be applied
- where in the stereo mix it should be
- which reverb effect and how much to apply

### definition bucket

When the definition JSON arrives it triggers the `renderer_compositor_main` function which spawns one `renderer_compositor_child` process per horizontal stripe 
of the output video that needs to be created, each stripe being written to the `final-parts` bucket. 

### final-parts bucket

Each stripe of the final video arrives in the `final-parts` bucket, triggering the renderer_final Lambda. If all the stripes are not there yet the 
Lambda dies. If they are all there, the stripes are combined together into a single video which is placed into the `preview` bucket.

### preview bucket

The preview video triggers the `post_production` lambda which normalises the audio and adds reverb. The resultant video is written to the `final` bucket.

###  final bucket

This is the finished video but there's one more task: to take a jpeg snapshot of the finished video.

## EFS and VPC Lambdas

Some processes create temporary files that are too large for the /tmp directory of a Lambda (max 512 MB on a standard Lambda). To get around this limitation, these Lambdas are creating temporary files in an EFS instance. For this process to work the EFS AND the Lambdas need to be be inside a VPC. Therefore there is terraform scaffolidng to do this, i.e. create the VPC and subnets, the EFS system and instantiate the Lambdas inside the VPC. The VPC has been created with minimal configuration and does NOT have access to the Internet.
**Limitations**: What this means is that Lambdas inside the VPC cannot invoke other Lambdas or access the Internet at the moment (e.g. to make API calls). There may be a concurrency issue later if the service becomes popular (more info on all this [here](https://aws.amazon.com/blogs/aws/new-a-shared-file-system-for-your-lambda-functions/) and [here](https://www.jeremydaly.com/mixing-vpc-and-non-vpc-lambda-functions-for-higher-performing-microservices/)

## Layers
The Lambdas (python and node) are all using Layers. These are libraries of common code that can be reused betweem Lambdas (such as python modules, npm libraries and even the ffmpeg binary). It makes the individual Lambda code smaller and more readable.
The layers we have are:
1. ffmpeg layer - contains the main ffmpeg binary. Generated by the build_ffmpeg_layer.sh
2. ffprobe layer- contains the ffprobe binary. Generated by the build_ffmpeg_layer.sh
3. python layer - contains python libraries. Generated by the build_python_layer.sh 
4. nodejs layer - contains the node modules. Shared by API and pipeline. Generated by the ../api/build_layer.sh
